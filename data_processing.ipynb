{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host=\"******\",user=\"******\",passwd=\"******\",database='******\',charset=\"******\", cursorclass=pymysql.cursors.DictCursor)\n",
    "#connection = pymysql.connect(host=\"localhost\",port=3308,user=\"root\",passwd=\"\",database='socialmedia_db')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(query):\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_start_date = '2024-09-01'                       \n",
    "overall_end_date = '2024-10-06'                     # End date (exclusive)\n",
    "\n",
    "pre_start_date = '2024-09-22'                       # Start date (inclusive)\n",
    "pre_end_date = '2024-09-29'                         # End date (exclusive)\n",
    "\n",
    "post_start_date = '2024-09-29'                      # Start date (inclusive)\n",
    "post_end_date = '2024-10-06'                        # End date (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_query = f\"\"\"SELECT * FROM fb_posts WHERE date(published_at) BETWEEN '{overall_start_date}' AND '{overall_end_date}'\"\"\"\n",
    "ig_query = f\"\"\"SELECT * FROM  instagram_posts WHERE date(published_at) BETWEEN '{overall_start_date}' AND '{overall_end_date}'\"\"\"\n",
    "tw_query = f\"\"\"SELECT * FROM twitter_tweet WHERE  date(published_at) BETWEEN '{overall_start_date}' AND '{overall_end_date}'\"\"\"\n",
    "yt_query = f\"\"\"SELECT * FROM youtube_data WHERE upload_date BETWEEN '{overall_start_date}' AND '{overall_end_date}'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data = fetch_data(fb_query)\n",
    "ig_data= fetch_data(ig_query)\n",
    "tw_data = fetch_data(tw_query)\n",
    "yt_data = fetch_data(yt_query)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\useer\\Downloads\\WB_Sep_29_Oct_5_data_dump')\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob(r'*.{}'.format(extension))]\n",
    "print(len(all_filenames))\n",
    "df_fb = pd.DataFrame()\n",
    "df_tw = pd.DataFrame()\n",
    "df_in = pd.DataFrame()\n",
    "for f in all_filenames:\n",
    "    df = pd.read_csv(f)\n",
    "    if 'facebook.com' in df['post_link'][0]:\n",
    "        df_fb = pd.concat([df_fb, df])\n",
    "    elif 'instagram.com' in df['post_link'][0]:\n",
    "        df_in = pd.concat([df_in, df])\n",
    "    else:\n",
    "        df_tw = pd.concat([df_tw, df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yt = pd.read_excel(r\"C:\\Users\\useer\\Downloads\\WB_Sep_29_Oct_5_data_dump\\YT WB Weekly Report 29nd Sep to 5th Oct 2024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb['presence_handle'] = df_fb['presence_handle'].fillna(df_fb['company'])\n",
    "df_fb = df_fb[['published_at', 'presence_handle', 'message', 'post_link', 'post_type', 'engagement_total', 'applause', 'conversation',\t'amplification', 'audience', 'engagement_rate_by_follower', 'video_views']]\n",
    "df_fb['published_at'] = df_fb['published_at'].astype('datetime64[ns]')\n",
    "df_fb.rename(columns={'audience': 'followers', 'applause':'reactions', 'conversation':'comments', 'amplification':'shares', 'audience':'followers'}, inplace=True)\n",
    "\n",
    "df_in = df_in[['published_at', 'presence_handle', 'message', 'post_link', 'post_type', 'engagement_total',\t'likes', 'comments', 'followers', 'engagement_rate_by_follower']]\n",
    "df_in['published_at'] = df_in['published_at'].astype('datetime64[ns]')\n",
    "\n",
    "df_tw = df_tw[['published_at', 'presence_handle', 'message', 'post_link', 'post_type',\t'engagement_total',\t'likes', 'retweets', 'replies',\t'video_views',\t'followers', 'engagement_rate_by_follower',\t'tweet_type', 'impressions']]\n",
    "df_tw['published_at'] = df_tw['published_at'].astype('datetime64[ns]')\n",
    "\n",
    "df_yt = df_yt[['Channel_name_x', 'video_id', 'upload_date', 'views', 'likes', 'comments', 'Subscribers']]\n",
    "df_yt.rename(columns={'Channel_name_x': 'presence_handle', 'upload_date':'published_at', 'Subscribers': 'followers'}, inplace=True)\n",
    "df_yt['published_at'] = df_yt['published_at'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data = fb_data[['published_at', 'username', 'message', 'post_link', 'post_type', 'engagement_total', 'reactions','comments',\t'shares', 'page_fans',\t'engagement_rate_by_follower','video_views']]\n",
    "fb_data.rename(columns={'username':'presence_handle', 'page_fans':'followers'}, inplace=True)\n",
    "fb_data['published_at'] = fb_data['published_at'].astype('datetime64[ns]')\n",
    "\n",
    "tw_data = tw_data[['published_at', 'username', 'tweet_text', 'tweet_url', 'media_type',\t'engagement',\t'likes', 'retweets', 'replies',\t'video_views',\t'followers', 'engagement_rate_by_follower',\t'tweet_type', 'impressions']]\n",
    "tw_data.rename(columns = {'username':'presence_handle', 'tweet_text':'message', 'tweet_url':'post_link', 'media_type':'post_type', 'engagement':'engagement_total'}, inplace=True)\n",
    "tw_data['published_at'] = tw_data['published_at'].astype('datetime64[ns]')\n",
    "\n",
    "ig_data = ig_data[['published_at', 'username', 'message', 'post_link', 'post_type', 'engagement',\t'likes', 'comments', 'followers', 'engagement_rate_by_follower']]\n",
    "ig_data.rename(columns = {'username':'presence_handle', 'engagement':'engagement_total'}, inplace = True)\n",
    "ig_data['published_at'] = ig_data['published_at'].astype('datetime64[ns]')\n",
    "\n",
    "yt_data = yt_data[['channel_name', 'video_id', 'upload_date', 'views', 'likes', 'comments', 'subscriber']]\n",
    "yt_data.rename(columns={'channel_name': 'presence_handle', 'upload_date':'published_at', 'subscriber': 'followers'}, inplace=True)\n",
    "yt_data['published_at'] = yt_data['published_at'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fb = pd.concat([df_fb, fb_data], axis=0).drop_duplicates(subset = 'post_link')\n",
    "df_tw = pd.concat([df_tw, tw_data], axis=0).drop_duplicates(subset = 'post_link')\n",
    "df_in = pd.concat([df_in, ig_data], axis=0).drop_duplicates(subset = 'post_link')\n",
    "df_yt = pd.concat([df_yt, yt_data], axis=0).drop_duplicates(subset = 'video_id')\n",
    "df_yt['engagement_total'] = df_yt['likes'] + df_yt['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'WB_Report_raw_data.xlsx', engine='openpyxl') as writer:\n",
    "    df_fb.to_excel(writer, sheet_name='Facebook', index=False)\n",
    "    df_tw.to_excel(writer, sheet_name='Twitter', index=False)\n",
    "    df_in.to_excel(writer, sheet_name='Instagram', index=False)\n",
    "    df_yt.to_excel(writer, sheet_name='YouTube', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pre = [df_fb, df_in, df_tw, df_yt]\n",
    "filtered_dfs_pre = []\n",
    "for df in dfs_pre:\n",
    "    filtered_df = df[(df['published_at'] >= pre_start_date) & (df['published_at'] < pre_end_date)]\n",
    "    filtered_dfs_pre.append(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_post = [df_fb, df_in, df_tw, df_yt]\n",
    "filtered_dfs_post = []\n",
    "for df in dfs_post:\n",
    "    filtered_df = df[(df['published_at'] >= post_start_date) & (df['published_at'] < post_end_date)]\n",
    "    filtered_dfs_post.append(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_overall = [df_fb, df_in, df_tw, df_yt]\n",
    "filtered_dfs_overall = []\n",
    "for df in dfs_overall:\n",
    "    filtered_df = df[(df['published_at'] >= overall_start_date) & (df['published_at'] < overall_end_date)]\n",
    "    filtered_dfs_overall.append(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_16736\\1104123152.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_16736\\1104123152.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n",
      "C:\\Users\\useer\\AppData\\Local\\Temp\\ipykernel_16736\\1104123152.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "for df in filtered_dfs_pre:\n",
    "    df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n",
    "    print(df['published_at'].nunique())\n",
    "\n",
    "for df in filtered_dfs_post:\n",
    "    df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n",
    "    print(df['published_at'].nunique())\n",
    "\n",
    "for df in filtered_dfs_overall:\n",
    "    df['published_at'] = df['published_at'].dt.strftime('%Y-%m-%d')\n",
    "    print(df['published_at'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_computer(dfs, duration = 7):\n",
    "    fb_agg = dfs[0].groupby('presence_handle').agg({\n",
    "        'video_views': 'mean',  \n",
    "        'engagement_total': 'sum',\n",
    "        'post_link':'nunique',\n",
    "        'followers': 'max',\n",
    "        'published_at': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    fb_agg.rename(columns={'video_views': 'Avg Video Views', 'post_link': 'Total Posts', 'engagement_total':'Total Engagement', 'followers':'Followers', 'published_at':'count_of_active_days'}, inplace=True)\n",
    "    fb_agg['Engagement Rate'] = fb_agg['Total Engagement'] * 100 / (fb_agg['Followers'] * duration)\n",
    "    fb_agg['Avg. Post Per Day'] = fb_agg['Total Posts'] / duration\n",
    "    fb_agg['Avg Engagement'] = fb_agg['Total Engagement'] / fb_agg['Total Posts']\n",
    "\n",
    "    in_agg = dfs[1].groupby('presence_handle').agg({ \n",
    "        'engagement_total': 'sum',\n",
    "        'post_link':'nunique',\n",
    "        'followers': 'max',\n",
    "        'published_at': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    in_agg.rename(columns={'post_link': 'Total Posts', 'engagement_total':'Total Engagement', 'followers':'Followers', 'published_at':'count_of_active_days'}, inplace=True)\n",
    "    in_agg['Engagement Rate'] = in_agg['Total Engagement'] * 100 / (in_agg['Followers'] * duration)\n",
    "    in_agg['Avg. Post Per Day'] = in_agg['Total Posts'] / duration\n",
    "    in_agg['Avg Engagement'] = in_agg['Total Engagement'] / in_agg['Total Posts']\n",
    "\n",
    "    tw_agg = dfs[2].groupby('presence_handle').agg({\n",
    "        'video_views': 'mean',  \n",
    "        'post_link':'nunique',\n",
    "        'engagement_total': 'sum',\n",
    "        'followers': 'max',\n",
    "        'impressions':'mean',\n",
    "        'published_at': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    tw_agg.rename(columns={'video_views': 'Avg Video Views', 'engagement_total':'Total Engagement', 'followers':'Followers', 'post_link': 'Total Posts','published_at':'count_of_active_days'}, inplace=True)\n",
    "    tw_agg['Engagement Rate'] = tw_agg['Total Engagement'] * 100 / (tw_agg['Followers'] * duration)\n",
    "    tw_agg['Avg. Post Per Day'] = tw_agg['Total Posts'] / duration\n",
    "    tw_agg['Avg Engagement'] = tw_agg['Total Engagement'] / tw_agg['Total Posts']\n",
    "\n",
    "    yt_agg = dfs[3].groupby('presence_handle').agg({\n",
    "        'views': 'sum',  \n",
    "        'likes': 'sum',\n",
    "        'comments':'sum',\n",
    "        'video_id':'nunique',\n",
    "        'followers': 'max',\n",
    "        'published_at': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    yt_agg['Total Engagement'] = yt_agg['likes'] + yt_agg['comments']\n",
    "    yt_agg.rename(columns={'views': 'Total Video Views', 'video_id': 'Total Posts', 'followers':'Followers', 'published_at':'count_of_active_days'}, inplace=True)\n",
    "    yt_agg['Engagement Rate'] = yt_agg['Total Engagement'] * 100 / (yt_agg['Followers'] * duration)\n",
    "    yt_agg['Avg. Post Per Day'] = yt_agg['Total Posts'] / duration\n",
    "    yt_agg['Avg Engagement'] = yt_agg['Total Engagement'] / yt_agg['Total Posts']\n",
    "    yt_agg['Avg Video Views'] = yt_agg['Total Video Views'] / yt_agg['Total Posts']\n",
    "\n",
    "    return [fb_agg, in_agg, tw_agg, yt_agg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_df = pd.read_excel(r\"F:\\Projects\\PPTX_env\\WB_weekly\\Party_mapping.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs_pre = metric_computer(filtered_dfs_pre)\n",
    "processed_dfs_post = metric_computer(filtered_dfs_post)\n",
    "processed_dfs_overall = metric_computer(filtered_dfs_overall, duration = filtered_dfs_overall[0]['published_at'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.ExcelWriter(f'WB_Report_data_{post_end_date}.xlsx', engine='openpyxl') as writer:\n",
    "    \n",
    "    pd.merge(mapping_df.dropna(subset = 'Facebook'), processed_dfs_pre[0], how='left', left_on = 'Facebook', right_on = 'presence_handle')[['Name','Facebook', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Facebook': 'presence_handle'}).to_excel(writer, sheet_name='Facebook_all_stats_pre_', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Instagram'), processed_dfs_pre[1], how='left', left_on = 'Instagram', right_on = 'presence_handle')[['Name','Instagram', 'mapping', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Instagram': 'presence_handle'}).to_excel(writer, sheet_name='Instagram_all_stats_pre_', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Twitter'), processed_dfs_pre[2], how='left', left_on = 'Twitter', right_on = 'presence_handle')[['Name','Twitter', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement', 'impressions']].rename(columns={'Twitter': 'presence_handle'}).to_excel(writer, sheet_name='Twitter_all_stats_pre_', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'YouTube'), processed_dfs_pre[3], how='left', left_on = 'YouTube', right_on = 'presence_handle')[['Name','YouTube', 'mapping', 'Total Video Views', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'YouTube': 'presence_handle'}).to_excel(writer, sheet_name='YouTube_all_stats_pre_', index=False)\n",
    "\n",
    "    pd.merge(mapping_df.dropna(subset = 'Facebook'), processed_dfs_post[0], how='left', left_on = 'Facebook', right_on = 'presence_handle')[['Name', 'Facebook', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Facebook': 'presence_handle'}).to_excel(writer, sheet_name='Facebook_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Instagram'), processed_dfs_post[1], how='left', left_on = 'Instagram', right_on = 'presence_handle')[['Name', 'Instagram', 'mapping', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Instagram': 'presence_handle'}).to_excel(writer, sheet_name='Instagram_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Twitter'), processed_dfs_post[2], how='left', left_on = 'Twitter', right_on = 'presence_handle')[['Name', 'Twitter', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement', 'impressions']].rename(columns={'Twitter': 'presence_handle'}).to_excel(writer, sheet_name='Twitter_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'YouTube'), processed_dfs_post[3], how='left', left_on = 'YouTube', right_on = 'presence_handle')[['Name','YouTube', 'mapping', 'Total Video Views', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'YouTube': 'presence_handle'}).to_excel(writer, sheet_name='YouTube_all_stats_post', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'WB_Report_data_{post_end_date}_overall.xlsx', engine='openpyxl') as writer:\n",
    "    pd.merge(mapping_df.dropna(subset = 'Facebook'), processed_dfs_overall[0], how='left', left_on = 'Facebook', right_on = 'presence_handle')[['Name','Facebook', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Facebook': 'presence_handle'}).to_excel(writer, sheet_name='Facebook_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Instagram'), processed_dfs_overall[1], how='left', left_on = 'Instagram', right_on = 'presence_handle')[['Name','Instagram', 'mapping', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'Instagram': 'presence_handle'}).to_excel(writer, sheet_name='Instagram_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'Twitter'), processed_dfs_overall[2], how='left', left_on = 'Twitter', right_on = 'presence_handle')[['Name','Twitter', 'mapping', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement', 'impressions']].rename(columns={'Twitter': 'presence_handle'}).to_excel(writer, sheet_name='Twitter_all_stats_post', index=False)\n",
    "    pd.merge(mapping_df.dropna(subset = 'YouTube'), processed_dfs_overall[3], how='left', left_on = 'YouTube', right_on = 'presence_handle')[['Name','YouTube', 'mapping', 'Total Video Views', 'Avg Video Views', 'Total Engagement', 'Total Posts', 'Followers', 'count_of_active_days', 'Engagement Rate', 'Avg. Post Per Day', 'Avg Engagement']].rename(columns={'YouTube': 'presence_handle'}).to_excel(writer, sheet_name='YouTube_all_stats_post', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = ['Facebook', 'Instagram', 'Twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_type_dfs = []\n",
    "\n",
    "for index, df in enumerate(filtered_dfs_post[:3]):\n",
    "    df = df.drop_duplicates(subset = ['post_link'])\n",
    "\n",
    "    grouped = df.groupby('presence_handle')['post_type'].value_counts()\n",
    "    result_df = grouped.reset_index(name='count')\n",
    "\n",
    "    missing_values = set(mapping_df[platforms[index]]) - set(result_df['presence_handle'])\n",
    "\n",
    "    missing_df = pd.DataFrame({\n",
    "        'presence_handle': list(missing_values)\n",
    "    })\n",
    "\n",
    "    result_df = pd.concat([result_df, missing_df], ignore_index=True)\n",
    "    post_type_dfs.append(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'WB_Report_data_{post_end_date}_post_dist.xlsx', engine='openpyxl') as writer:\n",
    "    pd.merge(mapping_df, post_type_dfs[0], how='left', left_on = 'Facebook', right_on = 'presence_handle')[['Name','presence_handle', 'mapping','post_type', 'count']].to_excel(writer, sheet_name='Facebook', index=False)\n",
    "    pd.merge(mapping_df, post_type_dfs[1], how='left', left_on = 'Instagram', right_on = 'presence_handle')[['Name','presence_handle', 'mapping','post_type', 'count']].to_excel(writer, sheet_name='Instagram', index=False)\n",
    "    pd.merge(mapping_df, post_type_dfs[2], how='left', left_on = 'Twitter', right_on = 'presence_handle')[['Name','presence_handle', 'mapping','post_type', 'count']].to_excel(writer, sheet_name='Twitter', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('WB_report_7_DMA.xlsx', engine='openpyxl') as writer:\n",
    "    excel_file = pd.ExcelFile('WB_Report_raw_data.xlsx')\n",
    "\n",
    "    for sheet_name in excel_file.sheet_names:\n",
    "        data = pd.read_excel('WB_Report_raw_data.xlsx', sheet_name = sheet_name)\n",
    "        dff = pd.DataFrame()\n",
    "        \n",
    "        for i in data['presence_handle'].unique():\n",
    "            data1 = data[data['presence_handle'] == i].copy()\n",
    "            data1['published_at'] = pd.to_datetime(data1['published_at']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Grouping the relevant data\n",
    "            if sheet_name == 'YouTube':\n",
    "                post_link_str = 'video_id'\n",
    "            else:\n",
    "                post_link_str = 'post_link'\n",
    "\n",
    "            engagement_total = data1[['published_at', 'engagement_total']].groupby(['published_at'])[['engagement_total']].sum().reset_index()\n",
    "            post_link = data1[['published_at', post_link_str]].groupby(['published_at'])[[post_link_str]].nunique().reset_index()\n",
    "            followers = data1[['published_at', 'followers']].groupby(['published_at'])[['followers']].max().reset_index()\n",
    "\n",
    "            # Set index for merging\n",
    "            engagement_total.set_index('published_at', inplace=True)\n",
    "            post_link.set_index('published_at', inplace=True)\n",
    "            followers.set_index('published_at', inplace=True)\n",
    "\n",
    "            # Combine the data into one dataframe\n",
    "            data2 = pd.concat([engagement_total, post_link, followers], axis=1).reset_index()\n",
    "\n",
    "            # Create the date range\n",
    "            date_range = pd.date_range(start = pre_start_date, end = pd.to_datetime(post_end_date) - pd.Timedelta(days=1))\n",
    "            date_range_df = pd.DataFrame(date_range, columns=['published_at'])\n",
    "            date_range_df['published_at'] = date_range_df['published_at'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Merge with the date range to include all dates\n",
    "            data2 = pd.merge(date_range_df, data2, on='published_at', how='left')\n",
    "\n",
    "            # Replace missing values appropriately\n",
    "            data2['engagement_total'] = data2['engagement_total'].fillna(0)\n",
    "            data2[post_link_str] = data2[post_link_str].fillna(0)\n",
    "\n",
    "            # Replace followers missing values with the mean of available values\n",
    "            data2['followers'] = data2['followers'].fillna(data2['followers'].mean())\n",
    "\n",
    "            # Rolling calculations for moving averages\n",
    "            data2['moving_sum_engagement'] = data2['engagement_total'].rolling(window=7).sum()\n",
    "            data2['moving_post_link'] = data2[post_link_str].rolling(window=7).sum()\n",
    "            data2['moving_followers'] = data2['followers'].rolling(window=7).max()\n",
    "            data2['moving_post_link'] = data2[post_link_str].rolling(window=7).mean()\n",
    "\n",
    "            # Calculate engagement rate and average engagement\n",
    "            data2['engagement_rate'] = (data2['moving_sum_engagement'] / data2['moving_followers'] * 100) / 7\n",
    "            data2['average_engagement'] = data2['moving_sum_engagement'] / data2[post_link_str].rolling(window=7).sum()\n",
    "            \n",
    "            # Create final dataframe with selected columns\n",
    "            df = data2[['published_at', 'engagement_rate', 'average_engagement','moving_post_link']].copy()\n",
    "            df['presence_handle'] = i\n",
    "\n",
    "            # Cross-tabulation for summarizing the engagement\n",
    "            crosstab = pd.crosstab(df['published_at'], df['presence_handle'], df['engagement_rate'], aggfunc='mean', dropna=False).reset_index()\n",
    "\n",
    "            # Concatenate the result to the final DataFrame\n",
    "            dff = pd.concat([dff, df], axis=0)\n",
    "\n",
    "        # Write the final dataframe for this sheet to the Excel file\n",
    "        dff.to_excel(writer, sheet_name = sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_dict = {\n",
    "#     \"UCm38ql6JxbY8Q3q6HMkeITw\": \"Dilip Ghosh\",\n",
    "#     \"UCuANW5toE4P8rab9GVoMTtA\": \"Suvendu Adhikari\",\n",
    "#     \"UCA1S8-aM-YCEJCg4mHj20HA\": \"Mamata Banerjee\",\n",
    "#     \"UCFZ628cJi0OP89l432blg9A\": \"Abhishek Banerjee\",\n",
    "#     \"drsujanchakraborty1\": \"Sujan Chakraborty\",\n",
    "#     \"bjp4bengal\": \"BJP\",\n",
    "#     \"aitcofficialyoutube\": \"AITC\",\n",
    "#     \"cpimwestbengalonline\": \"CPI(M)\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follower_df = pd.read_excel(r\"C:\\Users\\useer\\Downloads\\socialblade (1) (version 1).xlsb.xlsx\")\n",
    "# follower_df['platform']=follower_df['URL'].str.split('/').str[3]\n",
    "# follower_df['presence_handle']=follower_df['URL'].str.split('/').str[5]\n",
    "# follower_df['platform']=follower_df['platform'].apply(lambda x: x.capitalize() if x!='youtube' else \"YouTube\")\n",
    "# follower_df['Date'] = pd.to_datetime(follower_df['Date'])\n",
    "# follower_df = follower_df[(follower_df['Date'] >= pre_start_date) & (follower_df['Date'] < post_end_date)]\n",
    "# follower_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_df = pd.read_excel(r\"F:\\Projects\\PPTX_env\\WB_weekly\\Party_mapping.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_list = ['Mamata Banerjee', 'Abhishek Banerjee', 'Suvendu Adhikari', 'Dilip Ghosh', 'Adhir Ranjan Chowdhury', 'Md Salim', 'Sujan Chakraborty', 'AITC', 'BJP', 'INC', 'CPI(M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped_df = pd.DataFrame()\n",
    "# for platform in list(follower_df['platform'].unique()):\n",
    "#     sub_df = follower_df[follower_df['platform'] == platform]\n",
    "#     mapping_df[platform] = mapping_df[platform].str.lower()\n",
    "#     sub_df['presence_handle'] = sub_df['presence_handle'].str.lower()\n",
    "\n",
    "#     if platform != 'YouTube':\n",
    "#         mapped_sub_df = pd.merge(sub_df, mapping_df, left_on = 'presence_handle', right_on = platform)[['Date', 'followers', 'platform', 'Name']]\n",
    "#         # print(sub_df['presence_handle'].unique())\n",
    "#         # print(mapped_sub_df['Name'].unique())\n",
    "#         # print()\n",
    "#     else:\n",
    "#         sub_df['Name'] = sub_df['presence_handle'].map(channel_dict)\n",
    "#         mapped_sub_df = sub_df[['Date', 'followers', 'platform', 'Name']]\n",
    "    \n",
    "#     print(len(sub_df), len(mapped_sub_df))\n",
    "\n",
    "#     mapped_df = pd.concat([mapped_df, mapped_sub_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
